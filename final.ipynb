{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloads images from instagram of a particular username, and classifies images as human or non-human\n",
    "\n",
    "### To make the thing work, you need to enter your instagram password in the second last cell of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import Image, display\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directories of train and test, and splitting the photos randomly into 90% and 10% into train and test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test directories already created\n",
      "all necessary directories already created\n",
      "all necessary directories already created\n",
      "training and testing directories created and images added for  Cat\n",
      "training and testing directories created and images added for  Dog\n",
      "training and testing directories created and images added for  Human\n",
      "training and testing directories created and images added for  Not Human\n"
     ]
    }
   ],
   "source": [
    "dir_list = os.listdir('A:/python_data/Instagram Classifier/data orig')\n",
    "    \n",
    "\n",
    "try:\n",
    "    os.mkdir('A:/python_data/Instagram Classifier/data formatted/train')\n",
    "    os.mkdir('A:/python_data/Instagram Classifier/data formatted/test')\n",
    "    \n",
    "except:\n",
    "    print('Train and Test directories already created')\n",
    "    \n",
    "for item in dir_list:\n",
    "    try:\n",
    "        os.mkdir('A:/python_data/Instagram Classifier/data formatted/train/' + item)\n",
    "        os.mkdir('A:/python_data/Instagram Classifier/data formatted/test/' + item)\n",
    "    except:\n",
    "        print('all necessary directories already created')\n",
    "        \n",
    "SOURCE = 'A:/python_data/Instagram Classifier/data orig/'\n",
    "\n",
    "\n",
    "for item in dir_list:\n",
    "    #creating list of all images in each directory\n",
    "    dir_image_list = os.listdir(SOURCE + item + '/')\n",
    "    #we will append image file paths of all the images which are readable and are greater than 4kb\n",
    "    proper_images_list = []\n",
    "    \n",
    "    #going through the list of all images in the directory\n",
    "    for image in dir_image_list:\n",
    "        file_path = SOURCE + item + '/' + image\n",
    "        \n",
    "        #size of image should be greater than 4 kb\n",
    "        if os.path.getsize(file_path)/1024 > 4:\n",
    "            proper_images_list.append(image)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    length = len(proper_images_list)\n",
    "    \n",
    "    #splitting training and testing set into 90% and 10%\n",
    "    split_point = int(length *0.9)\n",
    "    \n",
    "    #shuffling the list\n",
    "    shuffled = random.sample(proper_images_list, length)\n",
    "    \n",
    "    train_proper_images_list = shuffled[:split_point]\n",
    "    test_proper_images_list = shuffled[split_point:]\n",
    "    \n",
    "    TRAINING = 'A:/python_data/Instagram Classifier/data formatted/train/' + item + '/'\n",
    "    TESTING = 'A:/python_data/Instagram Classifier/data formatted/test/' + item + '/'\n",
    "    \n",
    "    for file_name in train_proper_images_list:\n",
    "        try:\n",
    "            #this is a check of whether the system can read the image\n",
    "            #some images even though windows explorer opens them, tensorflow doesn't like it\n",
    "            #if the follwing line of code work, then there is no issue with the image\n",
    "            byteImg = Image.open(file_directory)\n",
    "            \n",
    "            copyfile(SOURCE + item + '/' + file_name , TRAINING + file_name)\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    for file_name in test_proper_images_list:\n",
    "        try:\n",
    "            copyfile(SOURCE + item + '/' + file_name , TESTING + file_name)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print('training and testing directories created and images added for ', item)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2122 images belonging to 4 classes.\n",
      "Found 2122 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (300, 300,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, (3,3),  activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3),  activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3),  activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "             optimizer = 'adam', \n",
    "             metrics= 'accuracy')\n",
    "\n",
    "#normalizing data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range =0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'A:/python_data/Instagram Classifier/data formatted/train/',\n",
    "    target_size = (300,300),\n",
    "    batch_size = 100,\n",
    "    class_mode = \"categorical\"\n",
    ")\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1 / 255,\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'A:/python_data/Instagram Classifier/data formatted/train/',\n",
    "    batch_size=100,\n",
    "    class_mode='categorical',\n",
    "    target_size=(300, 300)\n",
    ")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    final_model = tf.keras.models.load_model('my_model3.h5')\n",
    "    \n",
    "except:\n",
    "    final_model  = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch =22,\n",
    "    epochs = 7,\n",
    "    verbose = 1,\n",
    "    validation_data=validation_generator)\n",
    "    model.save('my_model4.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining predictor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "def predictor(img_dir):\n",
    "    img = image.load_img(img_dir, target_size = (300,300))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0) #increases the dimension of the array by one. if 1D, becomes 2D.\n",
    "                                    #axis = 0 ==> shape = (1, length)\n",
    "                                    #here, it changes shape from (300, 300, 3) to (1,300,300,3)\n",
    "    images = np.vstack([x]) #stacks the array vertically (the shape does not change for some reason)\n",
    "    classes = model.predict(images, batch_size = 10)\n",
    "    classes = np.squeeze(classes[0]) #remove excess dimensions\n",
    "    \n",
    "    if classes[0] == 0:\n",
    "        print('The image is NOT HUMAN')\n",
    "    else:\n",
    "        print('The image is HUMAN')\n",
    "\n",
    "\n",
    "#     print('The class of the image is ', np.squeeze(classes[0]))\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the main cell\n",
    "#### change the username we want to scrape\n",
    "#### also input the username you want to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the format:\n",
    "# instagram-scraper <username we want to scrape> -u <your username> -p <your password>   \n",
    "! instagram-scraper zane -u aagam.jain1999 -p ykXpC0Tw197Cx2JP \n",
    "\n",
    "instagram_username = input('please enter username you want to scrape')      \n",
    "listdir = os.listdir(instagram_username)\n",
    "\n",
    "for image_name in listdir:\n",
    "    image_path = instagram_username + '/' + image_name\n",
    "    predictor(image_path)\n",
    "display(Image(filename = image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shows the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.history.keys())\n",
    "\n",
    "accuracy = final_model.history['accuracy']\n",
    "val_accuracy = final_model.history['val_accuracy']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(accuracy)\n",
    "plt.plot(val_accuracy)\n",
    "# plt.xticks(color = 'white')\n",
    "# plt.yticks(color = 'white');\n",
    "\n",
    "# del plt.xticks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
